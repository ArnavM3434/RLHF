{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvaN1D1j5w-C",
        "outputId": "ca7a7915-8b69-401a-ef49-5ef18e007894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (0.17.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate) (2.8.0+cu126)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Downloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.24.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets accelerate trl peft tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n"
      ],
      "metadata": {
        "id": "BTqreisa533P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_AG57ef7ra0",
        "outputId": "1e90c3a5-18bf-46f7-fb3a-2f868164c225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c53y2M4561W",
        "outputId": "f9c13539-b4e4-474a-ae83-fb36493632d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workspace = 'SFT'\n",
        "import os\n",
        "os.chdir(f\"/content/drive/My Drive/{workspace}\")\n",
        "print(\"Current working dir:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9syFcYO5--w",
        "outputId": "6a4684cf-573e-4656-e031-62bde17e98aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working dir: /content/drive/My Drive/SFT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pretrained GPT2 Behavior"
      ],
      "metadata": {
        "id": "n70Tvn2K626J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\""
      ],
      "metadata": {
        "id": "3lq_sYXm6zd3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"auto\")"
      ],
      "metadata": {
        "id": "kC9_vrtA645u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZv8mhwv8Dn3",
        "outputId": "a0b965ab-2cdd-4007-f20d-7a02e428bcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "826a62345c40412d9f8b98e1cce3d69c",
            "a3afc1f4ee59411896f2249f4a01cf85",
            "31fcd768c1004b2b97ec200757ec2a0d",
            "fcfff099c277475c8081cf04e544b002",
            "a442bf826fc343f196bcfeee73406b55",
            "f991d08c126b43429a1b20134469e813",
            "813d10c8c7114f4c938f6a547c121fd7",
            "7b0fafe0fe524bcc8c6769621081f658",
            "4b7e069a54ea432f970f0e2914331166",
            "026a0d7fbd1448259f0ce001c69da52a",
            "617b125c3408463686ae8aec7051d821",
            "315d1f764d444879aa4b42b2fc66c990",
            "cf642d3017ea48eaaa47b35968b52346",
            "0dfe377e058f42908f9da5b0e572a761",
            "3e2da5aa271e48c8b0d83f3aae42f1dd",
            "ff55ba5142fd4447a8ce35b5d3b27f1f",
            "756ffb45f07b49cdbfe3bdb1193b925a",
            "3a88c7dcaee84ec8b9e401a80209d24a",
            "198055fff6854f7e8d164856f26382e0",
            "f5ef141729da4bc3920575c81931a6b7",
            "3bb09c325fb54c9e98c67143e820e270",
            "7cdedafbb233483c8bc69fba9ea5b05d",
            "de4e12ff87ab43549232c8cab9d7046a",
            "4daee6dd886e491ea22cc80d99b7a978",
            "51d2e526733948938271d4a1c981416a",
            "c53422d742f34fcf83ef438f78fd9da3",
            "9304bfd8d51d40299787e0487cbbf4cb",
            "a5a31d5f259f4e4c9a733e0c6d44c470",
            "efb2c9c5ed5f4312aace95e4c2b63b3e",
            "a27e56d0529843119b901b9184cdff73",
            "2cb44484ae534251bc34e29dfaf05058",
            "527308f8e16c456faeaa7dec7e479306",
            "663017d5daa7472b8e9fa4029ddbb421",
            "22ec27babe4a49c39c3807209a80dc3f",
            "0aaaeac100234bfa9db0aab69396dbc0",
            "39c67b5088844a70adc0f462077469c5",
            "f8e03102cf064cbaa1ea79ca6daa91a0",
            "494034b0326f4f12b7b3730170463ae6",
            "98dc5b8fbf97432b9a55c6f8cebb98b9",
            "4d7737e5c592443293e47b3015b5ecb2",
            "1d5787352b4c455da732524a6f2aa4a8",
            "7407a6125b014e639d53e990171592e4",
            "e429165288994232b7bd546b074e7db4",
            "cfc6c93b562e4136a4628c85d23e7445"
          ]
        },
        "id": "jTGD5fOW6-HE",
        "outputId": "b56e7d3c-4cec-4d74-a936-1a92a850adf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "826a62345c40412d9f8b98e1cce3d69c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "315d1f764d444879aa4b42b2fc66c990"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de4e12ff87ab43549232c8cab9d7046a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22ec27babe4a49c39c3807209a80dc3f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"EOS token:\", tokenizer.eos_token)\n",
        "print(\"EOS token ID:\", tokenizer.eos_token_id)\n",
        "print(\"PAD token:\", tokenizer.pad_token)\n",
        "print(\"PAD token ID:\", tokenizer.pad_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxE4clAaA-Jo",
        "outputId": "ddda8b89-9e21-4c97-e96f-6086bfbb15d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EOS token: <|endoftext|>\n",
            "EOS token ID: 50256\n",
            "PAD token: None\n",
            "PAD token ID: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "DopEpROuDKN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PAD token ID:\", tokenizer.pad_token_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB2B4XeDDOgd",
        "outputId": "b52f575f-7d4a-4ad0-9e23-d8501dbf3411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PAD token ID: 50256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenizer max length:\", tokenizer.model_max_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG0ClEdUBoqU",
        "outputId": "fbbc4303-cc95-4098-98ae-331fc43d795e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer max length: 1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.padding_side = 'right'"
      ],
      "metadata": {
        "id": "_EoEUmgVD0h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_prompts = [\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain reinforcement learning\",\n",
        "    \"How does PPO work?\",\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        num_beams=5,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=1.0,\n",
        "        do_sample=False,\n",
        "    )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\\n\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5IZU-Q57BeN",
        "outputId": "497be917-1383-497e-a818-1f8466a2c361"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is machine learning?\n",
            "Response: What is machine learning?\n",
            "\n",
            "Machine learning is the process by which a computer learns to perform a task. It is a process that can be done in a number of different ways.\n",
            "\n",
            "For example, machine learning can be used to train a computer to perform certain tasks. It can also be used as a way to learn new skills. For example, a machine learning algorithm can be trained to perform tasks that are difficult to perform in the real world, such as learning how to read a book or how to write a letter. It may also be able to teach a computer how to do certain tasks in a way that is not possible in a real world. In other words, it can teach a machine how to learn how to solve certain problems in a certain way.\n",
            ". Machine learning is one of the most important aspects of machine learning. It allows the computer to learn to perform specific tasks. For instance, a computer can learn to do a task that requires a certain amount of memory, or it can learn new tasks that require more memory. In this way, the computer learns how to perform the task in a specific way. This is called machine learning, or machine learning as it is known in the scientific community. For more information about machine learning and machine learning in general, see Machine Learning and Machine Learning in the Science of Science and Technology (SSTT).\n",
            "\n",
            "How can I use machine learning to help me learn more about science and technology? How can I improve my understanding of science and tech? What are some of the things I can do to improve my knowledge of science, technology, engineering, math, and math-related topics? How do I get involved in the community of scientists, engineers, and mathematicians that I work with? What is the best way to get involved with the SSTT, and how can I contribute to it? What can I do if I don't know what I'm doing? What do I need to know before I can contribute to the project? What should I do when I'm not sure what I should do, and what should I be doing when I know what to do? What if I have no idea what I want to do, or if I can't figure it out? What does it mean to be a scientist, engineer, or mathematician? How does it feel to be part of a community that is trying to improve the lives of so many people? What would you like to see in the future? What will you do if you don't have the resources to do what you need to do to\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Explain reinforcement learning\n",
            "Response: Explain reinforcement learning.\n",
            "\n",
            "In this post, I'll show you how you can use reinforcement learning to train your brain to recognize and respond appropriately to situations. I'll also show you a simple way to learn reinforcement learning in Python, and how to use it in your own projects. I hope you enjoy this post as much as I enjoyed writing it!\n",
            "\n",
            "If you want to learn more about reinforcement learning, check out my previous posts on reinforcement learning and reinforcement learning for Python.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Prompt: How does PPO work?\n",
            "Response: How does PPO work?\n",
            "\n",
            "PPO is an open source project that allows you to create and manage your own PPO projects. PPO is a free, open-source project that can be used by anyone who wants to create a PPO project.\n",
            "\n",
            "How do I get started with PPO\n",
            "\n",
            "You can start using PPO by following these steps:\n",
            "\n",
            "1. Download and install PPO from the PPO website\n",
            "\n",
            "2. Install PPO on your computer\n",
            "\n",
            "3. Create a new PPO account\n",
            "\n",
            "4. Create an account on PPO.com\n",
            "\n",
            "5. Sign in to your PPO username and password\n",
            "\n",
            "6. Click the \"Create Account\" button\n",
            "\n",
            "7. Click \"Create New PPO Account\"\n",
            "\n",
            "8. Enter the following information into the \"PPO Username and Password\" field\n",
            "\n",
            "9. Click OK\n",
            "\n",
            "10. You should now be able to use PPO with your existing PPO accounts.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Alpaca Dataset"
      ],
      "metadata": {
        "id": "CCYI4u2J8vE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"tatsu-lab/alpaca\")"
      ],
      "metadata": {
        "id": "2QUYoR348hge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "94370527fa9e45f1a02695c9e4fdc1e3",
            "8457a304afd342ac9764cac8152fa922",
            "e44d3d389bf1478e8975f12ca18dd1c4",
            "ecde4bc2072047b1b65bbcee29ba1ffd",
            "df2a4a9614714805b05d43077cf117bd",
            "87fbfc6066aa4e03b9bd66415adb2519",
            "dc7f4c6e80c34e7e8781eeab81fd7134",
            "f11af32f85494221a710f4512229b07d",
            "634ab5f4834a4cf7a5df628ba7da26e3",
            "e3356488401a483988cecd7810d8f51d",
            "bade423ab4cc4d70a38525718aa5f06c",
            "68941eac58864e03b465f14a3e81526a",
            "a1653bcab6e9416283b87683913e40b7",
            "e60b0c7b7f344d14be6aa796638f3195",
            "71a75c6b1b8e4e6ba7cd269f5b29dfa0",
            "326cdf9643204d8d9adc0334ac6133eb",
            "f24a7601d4474af999ade483aa61a890",
            "79ebbc60873d468f9c2819f9ae0c362f",
            "0adf90aee4264578aac4c6910e4430bd",
            "0d6d172268354f11938f7d88e5794378",
            "ea711a657f3a4ff7b2e1c25285044852",
            "9f2d689bbfbd4338a25f5a2bd7582cfa",
            "4462f619928545499227ba30d20fe853",
            "ffdf2c7d66cd4f0c871ced6df7c14cc5",
            "cf61f6a03eba4741b1d2966d23e9043f",
            "7269967c09ce477895f20847937e27e5",
            "6451aa6bf3dc4a6288e2f72f19811e74",
            "af1f0912d636426c95b582735c98cf34",
            "4bea9617c0c5495ca35b3656f6b1f248",
            "0455ec7c5e9f464f85527f84ee83c842",
            "c255d0b5d9f84eefb91b7b4524b47097",
            "634a7ecb88834712be48ea630f216580",
            "dea664af432a4ebf90de5674972d7ac2"
          ]
        },
        "outputId": "b7245309-17a6-4d4f-a5ea-5357eae51159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94370527fa9e45f1a02695c9e4fdc1e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001-a09b74b3ef9c3b(…):   0%|          | 0.00/24.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "68941eac58864e03b465f14a3e81526a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/52002 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4462f619928545499227ba30d20fe853"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1Rve8LM84Tr",
        "outputId": "0e53144e-609a-4969-9994-b6f359a7ad54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output', 'text'],\n",
              "        num_rows: 52002\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import DatasetDict\n",
        "split = dataset['train'].train_test_split(test_size=0.05, seed=42)\n",
        "dataset = DatasetDict({\n",
        "    'train': split['train'],\n",
        "    'validation': split['test']\n",
        "})"
      ],
      "metadata": {
        "id": "CrU4GcXK86tl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6H4zQJYK9Fcj",
        "outputId": "c5f31ace-b393-43ec-d7e6-cb866fbd2721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['instruction', 'input', 'output', 'text'],\n",
              "        num_rows: 49401\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['instruction', 'input', 'output', 'text'],\n",
              "        num_rows: 2601\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = dataset['train']\n",
        "val_ds = dataset['validation']\n",
        "train_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBe94f0o9IxV",
        "outputId": "7b3acf99-b1db-44f5-a12e-38763e6c02d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Given a sentence, change the verb to make it in the past tense',\n",
              " 'input': 'I enjoy going to the beach',\n",
              " 'output': 'I enjoyed going to the beach.',\n",
              " 'text': 'Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGiven a sentence, change the verb to make it in the past tense\\n\\n### Input:\\nI enjoy going to the beach\\n\\n### Response:\\nI enjoyed going to the beach.'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE7THif09RLE",
        "outputId": "7befddc3-0d0c-4f74-caeb-93a48ab2967c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Explain why the internet has become such an important tool.',\n",
              " 'input': '',\n",
              " 'output': 'The internet has become an essential tool for a variety of reasons, but primarily because it can provide near-instant access to a world of information. It enables people to connect with friends, family, and people from all over the world. It has also revolutionized the way people do business by allowing for online Sales and e-commerce. Additionally, it has allowed for the rapid spread of multimedia, such as music, videos, and images, as well as streaming services like Netflix. In many ways, the internet has become a vital part of our lives, connecting us with the world in ways that were never before possible.',\n",
              " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nExplain why the internet has become such an important tool.\\n\\n### Response:\\nThe internet has become an essential tool for a variety of reasons, but primarily because it can provide near-instant access to a world of information. It enables people to connect with friends, family, and people from all over the world. It has also revolutionized the way people do business by allowing for online Sales and e-commerce. Additionally, it has allowed for the rapid spread of multimedia, such as music, videos, and images, as well as streaming services like Netflix. In many ways, the internet has become a vital part of our lives, connecting us with the world in ways that were never before possible.'}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change to Standard Prompt Completion"
      ],
      "metadata": {
        "id": "E7OUgj0D9bZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(example):\n",
        "    prompt = f\"Human: {example['instruction']} {example['input']} \"\n",
        "    completion = f\"Assistant: {example['output']}\"\n",
        "    full_text = prompt + completion\n",
        "    tokenized = tokenizer(\n",
        "            full_text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=1024,\n",
        "            return_tensors=\"pt\",\n",
        "    )\n",
        "    #only want to compute loss on completion\n",
        "    prompt_len = len(tokenizer(prompt)[\"input_ids\"])\n",
        "    labels = tokenized[\"input_ids\"].clone()\n",
        "    labels[:, :prompt_len] = -100\n",
        "\n",
        "    #mask out padding (except the first pad token which is the eos token)\n",
        "    pad_token_id = tokenizer.eos_token_id\n",
        "    for i in range(labels.shape[0]):\n",
        "        eos_positions = (labels[i] == pad_token_id).nonzero(as_tuple=True)[0]\n",
        "        if len(eos_positions) > 1:\n",
        "            # Keep the first EOS (end of completion) and mask the rest (padding)\n",
        "            labels[i, eos_positions[1:]] = -100\n",
        "\n",
        "    # fraction = (labels.squeeze() != -100).float().mean()\n",
        "    # print(fraction)\n",
        "    return {\n",
        "            \"input_ids\": tokenized[\"input_ids\"].squeeze(),\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"].squeeze(),\n",
        "            \"labels\": labels.squeeze(),\n",
        "    }\n",
        "\n",
        "train_ds = train_ds.map(preprocess_function, remove_columns=[\"instruction\", \"input\", \"output\", \"text\"])\n",
        "val_ds = val_ds.map(preprocess_function, remove_columns=[\"instruction\", \"input\", \"output\", \"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "07f583ee2879403eb248ff34c769ba28",
            "1869373c39fa4be9ba75830c761259c6",
            "10b743034df44d37a89d5a2ad74f20bd",
            "cbb583a85da547d7ab491701e0eb7d1a",
            "63983264634944a1869cb6001763dc41",
            "b87106a63e6b4723ba50d4580a6b045f",
            "54e0c5af455f404c9e06b35ae40f3a4d",
            "af8c5908bdd34a1e85e83b0476649b24",
            "81aaf222900e42f893373ab9bcf27c0e",
            "789465eeb1664f66b8cb7fb9f58e4efe",
            "1f0b4f78f63149d793a0e7f4b6e98838",
            "160fe916dcf642dcaad62a446a336a46",
            "848a5fdd4c9142839ca690d6bd105f5b",
            "8327a6957eb9428ebe607053c155fed3",
            "7e4964794dac4c5bb9fb53b10530373c",
            "8059c39775394d6c92363ef05e74fdb6",
            "30657f943806490aaf4e8110cc499201",
            "ccc8cf3431514417b74e67db323f029f",
            "be8b289dde4e42bb959d4ab5517b71ab",
            "ca4bc1b2fa0c4e959db756871831ec6c",
            "4e2f62f200e6402e96313914c6a5676f",
            "2ac5ca0e52aa4219a57c9093b45f5cd9"
          ]
        },
        "id": "IPzuGVG19dP1",
        "outputId": "a1e19e56-8e5c-44a9-fabc-f9f71629a40f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/49401 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07f583ee2879403eb248ff34c769ba28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2601 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "160fe916dcf642dcaad62a446a336a46"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SFT Trainer"
      ],
      "metadata": {
        "id": "jaLbJYIqAL14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments"
      ],
      "metadata": {
        "id": "o7bE-CRCANS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Peft Config"
      ],
      "metadata": {
        "id": "VtIQNRoFA7zi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LORA_CONFIG = dict(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\"c_attn\", \"c_proj\", \"q_attn\", \"wte\", \"wpe\"],\n",
        "    lora_dropout=0.2,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "lora_config = LoraConfig(**LORA_CONFIG)"
      ],
      "metadata": {
        "id": "HhwQs-p_AaVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhaXDaqyBDFh",
        "outputId": "5302d373-0794-4801-f0df-f608f01667d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/layer.py:2174: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(model, \"checkpoints/checkpoint-700\")"
      ],
      "metadata": {
        "id": "teovoeFslUYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_trainable_params(model):\n",
        "    total = 0\n",
        "    trainable = 0\n",
        "    details = []\n",
        "    for n, p in model.named_parameters():\n",
        "        total += p.numel()\n",
        "        if p.requires_grad:\n",
        "            trainable += p.numel()\n",
        "            details.append(n)\n",
        "    print(f\"Trainable params: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\")\n",
        "    print(\"Example trainable params:\", details[:20])\n",
        "    return details"
      ],
      "metadata": {
        "id": "ZKORgvtpBLa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_trainable_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GNSZ0DTBRNn",
        "outputId": "aa59a1ee-df26-45bb-c642-b66d414fc37f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 0 / 129,373,984 (0.00%)\n",
            "Example trainable params: []\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, parameter in model.named_parameters():\n",
        "    if \"lora_\" in name:\n",
        "        parameter.requires_grad = True"
      ],
      "metadata": {
        "id": "Zu0DEVYGmztM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_trainable_params(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_BseSqrnCa4",
        "outputId": "edac9006-7f29-4641-ef46-1a02ef4477e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 4,934,176 / 129,373,984 (3.81%)\n",
            "Example trainable params: ['base_model.model.transformer.wte.lora_embedding_A.default', 'base_model.model.transformer.wte.lora_embedding_B.default', 'base_model.model.transformer.wpe.lora_embedding_A.default', 'base_model.model.transformer.wpe.lora_embedding_B.default', 'base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight', 'base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight', 'base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight', 'base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight', 'base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight', 'base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight', 'base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight', 'base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight', 'base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight', 'base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight', 'base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight', 'base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight', 'base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight', 'base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight', 'base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight', 'base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['base_model.model.transformer.wte.lora_embedding_A.default',\n",
              " 'base_model.model.transformer.wte.lora_embedding_B.default',\n",
              " 'base_model.model.transformer.wpe.lora_embedding_A.default',\n",
              " 'base_model.model.transformer.wpe.lora_embedding_B.default',\n",
              " 'base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight',\n",
              " 'base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight',\n",
              " 'base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir = \"./checkpoints\",\n",
        "    eval_strategy = 'steps',\n",
        "    per_device_train_batch_size = 4,\n",
        "    per_device_eval_batch_size = 4,\n",
        "    gradient_accumulation_steps = 4,\n",
        "    learning_rate = 2e-5,\n",
        "    num_train_epochs = 3,\n",
        "    lr_scheduler_type = 'cosine',\n",
        "    warmup_steps = 100,\n",
        "    save_steps = 50,\n",
        "    logging_strategy = \"steps\",\n",
        "    logging_steps = 50,\n",
        "    save_strategy = \"steps\",\n",
        "    save_total_limit = 2,\n",
        "    eval_steps = 200,\n",
        "  )"
      ],
      "metadata": {
        "id": "ziaxm9CmBTpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = train_ds,\n",
        "    eval_dataset = val_ds,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1UQZWMdE55l",
        "outputId": "0dbf28d6-60fb-4421-eca2-740b0ec66036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3362210723.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "1FLcbFMf_0UX",
        "outputId": "f87601de-c809-4d6b-cb9a-58b2901b25e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': 50256}.\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnavnmehta1\u001b[0m (\u001b[33marnavnmehta1-nutanix\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/SFT/wandb/run-20251025_182415-jlf00627</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/arnavnmehta1-nutanix/huggingface/runs/jlf00627' target=\"_blank\">frosty-shadow-3</a></strong> to <a href='https://wandb.ai/arnavnmehta1-nutanix/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/arnavnmehta1-nutanix/huggingface' target=\"_blank\">https://wandb.ai/arnavnmehta1-nutanix/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/arnavnmehta1-nutanix/huggingface/runs/jlf00627' target=\"_blank\">https://wandb.ai/arnavnmehta1-nutanix/huggingface/runs/jlf00627</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='9264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/9264 4:56:29 < 9:42:48, 0.18 it/s, Epoch 1.01/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.128300</td>\n",
              "      <td>2.115093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.155400</td>\n",
              "      <td>2.112847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>2.098500</td>\n",
              "      <td>2.112167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>2.257700</td>\n",
              "      <td>2.106889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>2.233700</td>\n",
              "      <td>2.102957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.279600</td>\n",
              "      <td>2.099492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>2.193100</td>\n",
              "      <td>2.095898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.254000</td>\n",
              "      <td>2.093679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.211100</td>\n",
              "      <td>2.092422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.211600</td>\n",
              "      <td>2.090225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>2.216400</td>\n",
              "      <td>2.087763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>2.241900</td>\n",
              "      <td>2.085438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>2.221400</td>\n",
              "      <td>2.083948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>2.210400</td>\n",
              "      <td>2.081313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.239700</td>\n",
              "      <td>2.079764</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}