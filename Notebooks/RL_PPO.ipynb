{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42346a8da2cc4e9780537edfc53793f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36bc4b158ddd4425bb0209ca7e8cc06b",
              "IPY_MODEL_22174bf368294dcfa43f390e2e4b761c",
              "IPY_MODEL_142346715d244688b585e4e9873156d8",
              "IPY_MODEL_c049dc04795e498a9c78d04cae7de4e6",
              "IPY_MODEL_f82f24930d7e451fa74dab79d8c18f96"
            ],
            "layout": "IPY_MODEL_9b25f70bac9644729c90b4a10ccde293"
          }
        },
        "36bc4b158ddd4425bb0209ca7e8cc06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26108e72a5c14ba182a4656f0a1ad5df",
            "placeholder": "​",
            "style": "IPY_MODEL_12da906a63254552bc1c57adba080dbb",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "22174bf368294dcfa43f390e2e4b761c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_d3aee414e04949c9a22eb08defa55dd5",
            "placeholder": "​",
            "style": "IPY_MODEL_77e1f8e439cf4cce9ae4e6766b2041f1",
            "value": ""
          }
        },
        "142346715d244688b585e4e9873156d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_8a72b0f17a4c40e4a1ec3b09b2859137",
            "style": "IPY_MODEL_168a9912a4ab4ca6890abffd69ff3f8b",
            "value": true
          }
        },
        "c049dc04795e498a9c78d04cae7de4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7b3df57bfa1e434a93cc7fec31d80828",
            "style": "IPY_MODEL_1ab2879fae1f4728a95efaff5a869e64",
            "tooltip": ""
          }
        },
        "f82f24930d7e451fa74dab79d8c18f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58230602811c41dc9c223d9a79176eee",
            "placeholder": "​",
            "style": "IPY_MODEL_c0f1db3f98b9433eb067b6dcfd1d43af",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "9b25f70bac9644729c90b4a10ccde293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "26108e72a5c14ba182a4656f0a1ad5df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12da906a63254552bc1c57adba080dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3aee414e04949c9a22eb08defa55dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e1f8e439cf4cce9ae4e6766b2041f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a72b0f17a4c40e4a1ec3b09b2859137": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "168a9912a4ab4ca6890abffd69ff3f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b3df57bfa1e434a93cc7fec31d80828": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab2879fae1f4728a95efaff5a869e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "58230602811c41dc9c223d9a79176eee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0f1db3f98b9433eb067b6dcfd1d43af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Load SFT and Reward Model"
      ],
      "metadata": {
        "id": "IabwEx56JrDX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb1nBV7S7Fxd",
        "outputId": "0467ee9c-44d9-4677-fdfc-aceb468e48a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl==0.11 in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.12/dist-packages (from trl==0.11) (0.9.35)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.12/dist-packages (from trl==0.11) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.5.11->trl==0.11) (0.17.0)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.5.11->trl==0.11) (13.9.4)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.5.11->trl==0.11) (1.7.2)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from tyro>=0.5.11->trl==0.11) (4.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.11) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.11) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install trl==0.11 transformers accelerate datasets torch\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any\n",
        "import glob\n",
        "import shutil\n",
        "import wandb\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup"
      ],
      "metadata": {
        "id": "rnMrmJihJpKC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import create_reference_model"
      ],
      "metadata": {
        "id": "nsiBPRg4Dh07"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpZ1GZguJzZQ",
        "outputId": "e5d04ef4-4c18-41ef-a018-9f7f6cfe5a2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "workspace = 'PPO-Real'"
      ],
      "metadata": {
        "id": "ETN2in3XJ1RA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(f\"/content/drive/My Drive/{workspace}\")\n",
        "print(\"Current working dir:\", os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdhIAyItJ3R2",
        "outputId": "452a134f-8595-4bd6-a401-8f641f378e9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working dir: /content/drive/My Drive/PPO-Real\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331,
          "referenced_widgets": [
            "42346a8da2cc4e9780537edfc53793f9",
            "36bc4b158ddd4425bb0209ca7e8cc06b",
            "22174bf368294dcfa43f390e2e4b761c",
            "142346715d244688b585e4e9873156d8",
            "c049dc04795e498a9c78d04cae7de4e6",
            "f82f24930d7e451fa74dab79d8c18f96",
            "9b25f70bac9644729c90b4a10ccde293",
            "26108e72a5c14ba182a4656f0a1ad5df",
            "12da906a63254552bc1c57adba080dbb",
            "d3aee414e04949c9a22eb08defa55dd5",
            "77e1f8e439cf4cce9ae4e6766b2041f1",
            "8a72b0f17a4c40e4a1ec3b09b2859137",
            "168a9912a4ab4ca6890abffd69ff3f8b",
            "7b3df57bfa1e434a93cc7fec31d80828",
            "1ab2879fae1f4728a95efaff5a869e64",
            "58230602811c41dc9c223d9a79176eee",
            "c0f1db3f98b9433eb067b6dcfd1d43af"
          ]
        },
        "id": "1Qi2HPuoJ48L",
        "outputId": "2dc95eb8-980e-489d-e986-7a0f470ce111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42346a8da2cc4e9780537edfc53793f9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKP35sKps1GJ",
        "outputId": "46797894-1962-4b04-9252-655f533e3219"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marnavnmehta1\u001b[0m (\u001b[33marnavnmehta1-nutanix\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrOHybJjRT9-",
        "outputId": "0375d921-879a-4f3e-a99f-0a38dfb2c557"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from trl import AutoModelForCausalLMWithValueHead\n",
        "\n",
        "base_model = \"gpt2\""
      ],
      "metadata": {
        "id": "jTINaoffJ8RG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "auUxGdC6cTu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3debc45-31f6-4999-8813-14c604e14dc7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model = AutoModelForCausalLMWithValueHead.from_pretrained(\"ArnavM3434/gpt2-alpaca-second-try\")"
      ],
      "metadata": {
        "id": "W3NBPuxxA90K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1c6bf82-e37c-46c7-d9c8-276f3d16092d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from 'ArnavM3434/gpt2-alpaca-second-try', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n",
            "WARNING:root:A <class 'peft.peft_model.PeftModelForCausalLM'> model is loaded from 'ArnavM3434/gpt2-alpaca-second-try', and no v_head weight is found. This IS expected if you are not resuming PPO training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "policy_model.to(device)\n",
        "test_prompts = [\n",
        "    \"What is machine learning?\",\n",
        "    \"Explain reinforcement learning\",\n",
        "    \"How does PPO work?\",\n",
        "]\n",
        "\n",
        "for prompt in test_prompts:\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    outputs = policy_model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=512,\n",
        "        num_beams=5,\n",
        "        early_stopping=True,\n",
        "        no_repeat_ngram_size=3,\n",
        "        length_penalty=1.0,\n",
        "        do_sample=False,\n",
        "    )\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Response: {response}\\n\")\n",
        "    print(\"-\" * 80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZTH2rNQG5M4",
        "outputId": "5a594817-92d6-4d00-beff-e4c71c1be5dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is machine learning?\n",
            "Response: What is machine learning?\n",
            "Machine learning is a type of artificial intelligence (AI) that uses machine learning algorithms to analyze data and create predictive models. Machine learning algorithms can be used to identify patterns in data, predict patterns in the data, and then use those patterns to predict future outcomes. This type of machine learning can be applied to a wide range of industries, such as healthcare, transportation, and financial services.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Explain reinforcement learning\n",
            "Response: Explain reinforcement learning. Reinforcement learning is the process by which a neural network is trained to learn a task. It involves learning a set of inputs and outputs, and then training the network to perform the task. In reinforcement learning, the network learns from the input and outputs of the task, and when the network is able to perform a task correctly, it is rewarded with a reward. In other words, reinforcement learning can be used to train networks to perform complex tasks.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Prompt: How does PPO work?\n",
            "Response: How does PPO work?\n",
            "\n",
            "PPO works by sending a message to the user via email or text message. The message is then sent to the PPO server, where it is processed and sent back to the sender. PPO can also be used to send messages to other users, such as by sending an email to a friend or family member, or sending a text message to someone else.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ref_model = create_reference_model(policy_model)"
      ],
      "metadata": {
        "id": "o5ShWo8TDYaV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in ref_model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "zdhnpEHL89N_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_trainable_params(model):\n",
        "    total = 0\n",
        "    trainable = 0\n",
        "    details = []\n",
        "    for n, p in model.named_parameters():\n",
        "        total += p.numel()\n",
        "        if p.requires_grad:\n",
        "            trainable += p.numel()\n",
        "            details.append(n)\n",
        "    print(f\"Trainable params: {trainable:,} / {total:,} ({100 * trainable / total:.2f}%)\")\n",
        "    print(\"Example trainable params:\", details[:20])\n",
        "    return details"
      ],
      "metadata": {
        "id": "8pXt2VRWNj-4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_trainable_params(policy_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0buQl2VsNkm5",
        "outputId": "e6c0a5e2-6fcf-4618-f6cf-d6fbff8c5323"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 769 / 129,374,753 (0.00%)\n",
            "Example trainable params: ['v_head.summary.weight', 'v_head.summary.bias']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['v_head.summary.weight', 'v_head.summary.bias']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_trainable(model):\n",
        "  for name, param in model.named_parameters():\n",
        "      if \"lora_\" in name or \"v_head\" in name:\n",
        "          param.requires_grad = True\n",
        "      else:\n",
        "          param.requires_grad = False"
      ],
      "metadata": {
        "id": "lFa7el7gNoag"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_trainable(policy_model)"
      ],
      "metadata": {
        "id": "-5nlJfGmNpTh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_trainable_params(policy_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBAGvUv2OPy6",
        "outputId": "57548a78-bb90-470f-a253-6fe25235b2d9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 4,934,945 / 129,374,753 (3.81%)\n",
            "Example trainable params: ['pretrained_model.base_model.model.transformer.wte.lora_embedding_A.default', 'pretrained_model.base_model.model.transformer.wte.lora_embedding_B.default', 'pretrained_model.base_model.model.transformer.wpe.lora_embedding_A.default', 'pretrained_model.base_model.model.transformer.wpe.lora_embedding_B.default', 'pretrained_model.base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight', 'pretrained_model.base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight', 'pretrained_model.base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pretrained_model.base_model.model.transformer.wte.lora_embedding_A.default',\n",
              " 'pretrained_model.base_model.model.transformer.wte.lora_embedding_B.default',\n",
              " 'pretrained_model.base_model.model.transformer.wpe.lora_embedding_A.default',\n",
              " 'pretrained_model.base_model.model.transformer.wpe.lora_embedding_B.default',\n",
              " 'pretrained_model.base_model.model.transformer.h.0.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.0.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.0.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.0.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.0.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.0.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.1.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.1.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.1.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.1.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.1.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.1.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.2.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.2.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.2.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.2.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.2.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.2.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.3.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.3.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.3.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.3.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.3.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.3.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.4.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.4.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.4.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.4.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.4.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.4.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.5.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.5.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.5.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.5.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.5.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.5.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.6.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.6.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.6.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.6.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.6.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.6.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.7.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.7.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.7.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.7.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.7.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.7.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.8.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.8.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.8.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.8.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.8.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.8.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.9.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.9.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.9.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.9.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.9.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.9.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.10.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.10.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.10.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.10.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.10.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.10.mlp.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.11.attn.c_attn.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.11.attn.c_attn.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.11.attn.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.11.attn.c_proj.lora_B.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.11.mlp.c_proj.lora_A.default.weight',\n",
              " 'pretrained_model.base_model.model.transformer.h.11.mlp.c_proj.lora_B.default.weight',\n",
              " 'v_head.summary.weight',\n",
              " 'v_head.summary.bias']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Reward Model"
      ],
      "metadata": {
        "id": "2Xdq4ODzOg_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model = AutoModelForSequenceClassification.from_pretrained(\"OpenAssistant/reward-model-deberta-v3-base\")\n",
        "reward_tokenizer = AutoTokenizer.from_pretrained(\"OpenAssistant/reward-model-deberta-v3-base\")"
      ],
      "metadata": {
        "id": "4FO9rFD-OiKH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inspect_trainable_params(reward_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlJIXZ3CXIQx",
        "outputId": "5c6f4539-9387-460e-ec5a-913c8769d899"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 184,422,913 / 184,422,913 (100.00%)\n",
            "Example trainable params: ['deberta.embeddings.word_embeddings.weight', 'deberta.embeddings.LayerNorm.weight', 'deberta.embeddings.LayerNorm.bias', 'deberta.encoder.layer.0.attention.self.query_proj.weight', 'deberta.encoder.layer.0.attention.self.query_proj.bias', 'deberta.encoder.layer.0.attention.self.key_proj.weight', 'deberta.encoder.layer.0.attention.self.key_proj.bias', 'deberta.encoder.layer.0.attention.self.value_proj.weight', 'deberta.encoder.layer.0.attention.self.value_proj.bias', 'deberta.encoder.layer.0.attention.output.dense.weight', 'deberta.encoder.layer.0.attention.output.dense.bias', 'deberta.encoder.layer.0.attention.output.LayerNorm.weight', 'deberta.encoder.layer.0.attention.output.LayerNorm.bias', 'deberta.encoder.layer.0.intermediate.dense.weight', 'deberta.encoder.layer.0.intermediate.dense.bias', 'deberta.encoder.layer.0.output.dense.weight', 'deberta.encoder.layer.0.output.dense.bias', 'deberta.encoder.layer.0.output.LayerNorm.weight', 'deberta.encoder.layer.0.output.LayerNorm.bias', 'deberta.encoder.layer.1.attention.self.query_proj.weight']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deberta.embeddings.word_embeddings.weight',\n",
              " 'deberta.embeddings.LayerNorm.weight',\n",
              " 'deberta.embeddings.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.0.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.0.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.0.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.0.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.0.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.0.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.0.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.0.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.0.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.0.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.0.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.0.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.0.output.dense.weight',\n",
              " 'deberta.encoder.layer.0.output.dense.bias',\n",
              " 'deberta.encoder.layer.0.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.0.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.1.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.1.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.1.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.1.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.1.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.1.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.1.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.1.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.1.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.1.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.1.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.1.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.1.output.dense.weight',\n",
              " 'deberta.encoder.layer.1.output.dense.bias',\n",
              " 'deberta.encoder.layer.1.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.1.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.2.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.2.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.2.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.2.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.2.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.2.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.2.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.2.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.2.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.2.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.2.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.2.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.2.output.dense.weight',\n",
              " 'deberta.encoder.layer.2.output.dense.bias',\n",
              " 'deberta.encoder.layer.2.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.2.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.3.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.3.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.3.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.3.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.3.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.3.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.3.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.3.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.3.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.3.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.3.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.3.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.3.output.dense.weight',\n",
              " 'deberta.encoder.layer.3.output.dense.bias',\n",
              " 'deberta.encoder.layer.3.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.3.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.4.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.4.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.4.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.4.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.4.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.4.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.4.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.4.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.4.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.4.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.4.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.4.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.4.output.dense.weight',\n",
              " 'deberta.encoder.layer.4.output.dense.bias',\n",
              " 'deberta.encoder.layer.4.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.4.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.5.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.5.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.5.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.5.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.5.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.5.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.5.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.5.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.5.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.5.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.5.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.5.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.5.output.dense.weight',\n",
              " 'deberta.encoder.layer.5.output.dense.bias',\n",
              " 'deberta.encoder.layer.5.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.5.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.6.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.6.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.6.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.6.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.6.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.6.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.6.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.6.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.6.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.6.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.6.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.6.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.6.output.dense.weight',\n",
              " 'deberta.encoder.layer.6.output.dense.bias',\n",
              " 'deberta.encoder.layer.6.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.6.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.7.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.7.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.7.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.7.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.7.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.7.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.7.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.7.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.7.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.7.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.7.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.7.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.7.output.dense.weight',\n",
              " 'deberta.encoder.layer.7.output.dense.bias',\n",
              " 'deberta.encoder.layer.7.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.7.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.8.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.8.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.8.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.8.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.8.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.8.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.8.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.8.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.8.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.8.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.8.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.8.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.8.output.dense.weight',\n",
              " 'deberta.encoder.layer.8.output.dense.bias',\n",
              " 'deberta.encoder.layer.8.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.8.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.9.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.9.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.9.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.9.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.9.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.9.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.9.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.9.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.9.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.9.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.9.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.9.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.9.output.dense.weight',\n",
              " 'deberta.encoder.layer.9.output.dense.bias',\n",
              " 'deberta.encoder.layer.9.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.9.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.10.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.10.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.10.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.10.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.10.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.10.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.10.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.10.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.10.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.10.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.10.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.10.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.10.output.dense.weight',\n",
              " 'deberta.encoder.layer.10.output.dense.bias',\n",
              " 'deberta.encoder.layer.10.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.10.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.11.attention.self.query_proj.weight',\n",
              " 'deberta.encoder.layer.11.attention.self.query_proj.bias',\n",
              " 'deberta.encoder.layer.11.attention.self.key_proj.weight',\n",
              " 'deberta.encoder.layer.11.attention.self.key_proj.bias',\n",
              " 'deberta.encoder.layer.11.attention.self.value_proj.weight',\n",
              " 'deberta.encoder.layer.11.attention.self.value_proj.bias',\n",
              " 'deberta.encoder.layer.11.attention.output.dense.weight',\n",
              " 'deberta.encoder.layer.11.attention.output.dense.bias',\n",
              " 'deberta.encoder.layer.11.attention.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.11.attention.output.LayerNorm.bias',\n",
              " 'deberta.encoder.layer.11.intermediate.dense.weight',\n",
              " 'deberta.encoder.layer.11.intermediate.dense.bias',\n",
              " 'deberta.encoder.layer.11.output.dense.weight',\n",
              " 'deberta.encoder.layer.11.output.dense.bias',\n",
              " 'deberta.encoder.layer.11.output.LayerNorm.weight',\n",
              " 'deberta.encoder.layer.11.output.LayerNorm.bias',\n",
              " 'deberta.encoder.rel_embeddings.weight',\n",
              " 'deberta.encoder.LayerNorm.weight',\n",
              " 'deberta.encoder.LayerNorm.bias',\n",
              " 'pooler.dense.weight',\n",
              " 'pooler.dense.bias',\n",
              " 'classifier.weight',\n",
              " 'classifier.bias']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUe0PJzzXgz2",
        "outputId": "af19d2fe-9c37-4c61-9d9f-e591838dbf9e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2ForSequenceClassification(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reward_model.eval()"
      ],
      "metadata": {
        "id": "9d9-WA47OmvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7238266b-340c-45f0-aff0-dc7c3d1f9824"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DebertaV2ForSequenceClassification(\n",
              "  (deberta): DebertaV2Model(\n",
              "    (embeddings): DebertaV2Embeddings(\n",
              "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): DebertaV2Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x DebertaV2Layer(\n",
              "          (attention): DebertaV2Attention(\n",
              "            (self): DisentangledSelfAttention(\n",
              "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (pos_dropout): Dropout(p=0.1, inplace=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): DebertaV2SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): DebertaV2Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): DebertaV2Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (rel_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (pooler): ContextPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "  )\n",
              "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in reward_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "urWgFzR59GRH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Prompt Dataset"
      ],
      "metadata": {
        "id": "TYV7eTZ_YMy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"tatsu-lab/alpaca\", split=\"train\")\n",
        "\n",
        "dataset[0]"
      ],
      "metadata": {
        "id": "KS86GuOZoZip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3bbdf6-5055-4794-abea-a2af699811fb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Give three tips for staying healthy.',\n",
              " 'input': '',\n",
              " 'output': '1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.',\n",
              " 'text': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nGive three tips for staying healthy.\\n\\n### Response:\\n1.Eat a balanced diet and make sure to include plenty of fruits and vegetables. \\n2. Exercise regularly to keep your body active and strong. \\n3. Get enough sleep and maintain a consistent sleep schedule.'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzgyMw1n2LdB",
        "outputId": "41a9da7b-298c-4c81-9a75-14e621ebfa7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['instruction', 'input', 'output', 'text'],\n",
              "    num_rows: 52002\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns([\"output\", \"text\"])"
      ],
      "metadata": {
        "id": "9fRIed2p2AE4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX034WyiTDgV",
        "outputId": "f4b73266-5ca9-4abd-a88b-5d1fbe73f339"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'Give three tips for staying healthy.', 'input': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sample):\n",
        "    sample[\"query\"] = f\"Human: {sample['instruction']} {sample['input']} Assistant: \"\n",
        "    sample[\"input_ids\"] = tokenizer.encode(sample[\"query\"], padding = \"max_length\", truncation = True, max_length = 128)\n",
        "    return sample\n",
        "\n",
        "tokenized_dataset = dataset.map(\n",
        "    tokenize,\n",
        "    batched=False,\n",
        "    remove_columns = [\"instruction\", \"input\"]\n",
        ")"
      ],
      "metadata": {
        "id": "qjyNc0oN2Ii3"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset[0]['query']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IQAg1myA3Pqb",
        "outputId": "ee33dadd-7db5-4b35-9459-3d94c9847845"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Human: Give three tips for staying healthy.  Assistant: '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PPO"
      ],
      "metadata": {
        "id": "J9LkBitHp2k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import PPOTrainer, PPOConfig\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dEKPzi8GqACb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = PPOConfig(\n",
        "    model_name=\"gpt2\",\n",
        "    learning_rate=5e-7,\n",
        "    batch_size=4,\n",
        "    mini_batch_size=2,\n",
        "    gradient_accumulation_steps=1,\n",
        "    log_with=\"wandb\",\n",
        "    target_kl=2.0,\n",
        "    cliprange=0.05,\n",
        "    cliprange_value=0.1,\n",
        "    vf_coef=0.1,\n",
        "    init_kl_coef=0.5,\n",
        "    adap_kl_ctrl=True,\n",
        "    gamma=0.99,\n",
        "    lam=0.95,\n",
        "    ppo_epochs=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rm7aZHtVkpk",
        "outputId": "59d26618-763a-46a1-c9d2-c2520d832fb3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_config.py:207: FutureWarning: `PPOConfig` is deprecated and will be removed in the future. Please use `PPOv2Config` with `PPOv2Trainer` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ppo_trainer = PPOTrainer(\n",
        "    model=policy_model,\n",
        "    config=config,\n",
        "    dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    ref_model = ref_model\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        },
        "id": "NHHuoMlxVoio",
        "outputId": "d56244f1-f394-425d-b770-e4d06aec2f0f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:193: FutureWarning: `PPOTrainer` is deprecated and will be removed in trl v0.12. Please use `PPOv2Trainer` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>env/reward_mean</td><td>▂▁▁▃▄▃▃▄▄▃▄▄▃▂▃▂▅▄█▃▄▂▃▃▂▃▃▃▇▂▆▆▁</td></tr><tr><td>env/reward_std</td><td>▄▅▄▄▄▅▅▅▆▃▃▅▅▅▄▅█▅▆▃▆▃▅▅▅▃▅▅▅▅▁▅▅</td></tr><tr><td>objective/entropy</td><td>▅▃▅▃█▄▆▅▅▃▅▄▄▅▂█▇▃▄▄▆▄▄▇▂▃▅▆▄▁▄▇▅</td></tr><tr><td>objective/kl</td><td>▇█▄▅▂▃▇▅▄▄▅▁▄▆▇▅▄▃▄▄▂▆▃▂▃▃▃▄▁▃▂█▃</td></tr><tr><td>objective/kl_coef</td><td>▁▂▃▃▄▃▃▃▄▄▅▆▅▅▆▆▇▇▆▇█▇█▇▆▆▅▄▅▄▃▂▃</td></tr><tr><td>ppo/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ppo/loss/policy</td><td>▂▅▁▂▂▂▂▂▂▂▂▁▂▂▃▂▂▂▂▂▂▂▃▂▂▂▁▂▂█▂▂▂</td></tr><tr><td>ppo/loss/total</td><td>▇▄▇▄▇▂▅▅▆▂▆▅▅▃▅▇▄▄▂▄▁▇█▃▆▃▂▄▇█▆▄▃</td></tr><tr><td>ppo/loss/value</td><td>▇▃█▅▇▃▅▅▇▃▆▆▅▃▅█▄▅▂▄▁▇█▄▆▄▂▅█▆▆▄▃</td></tr><tr><td>ppo/mean_non_score_reward</td><td>▃▁▅▅▇▆▃▅▆▅▅█▆▄▂▅▆▆▅▅▇▄▇▇▆▆▇▆█▆▇▃▆</td></tr><tr><td>+25</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>env/reward_mean</td><td>-0.0</td></tr><tr><td>env/reward_std</td><td>1</td></tr><tr><td>objective/entropy</td><td>187.76193</td></tr><tr><td>objective/kl</td><td>4.40438</td></tr><tr><td>objective/kl_coef</td><td>0.10002</td></tr><tr><td>ppo/learning_rate</td><td>0.0</td></tr><tr><td>ppo/loss/policy</td><td>0.00049</td></tr><tr><td>ppo/loss/total</td><td>0.98053</td></tr><tr><td>ppo/loss/value</td><td>9.80045</td></tr><tr><td>ppo/mean_non_score_reward</td><td>-0.0079</td></tr><tr><td>+27</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cool-deluge-41</strong> at: <a href='https://wandb.ai/arnavnmehta1-nutanix/trl/runs/qq2necom' target=\"_blank\">https://wandb.ai/arnavnmehta1-nutanix/trl/runs/qq2necom</a><br> View project at: <a href='https://wandb.ai/arnavnmehta1-nutanix/trl' target=\"_blank\">https://wandb.ai/arnavnmehta1-nutanix/trl</a><br>Synced 5 W&B file(s), 33 media file(s), 68 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251027_175008-qq2necom/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/My Drive/PPO-Real/wandb/run-20251027_175327-bkzr6a9c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/arnavnmehta1-nutanix/trl/runs/bkzr6a9c' target=\"_blank\">toasty-pyramid-42</a></strong> to <a href='https://wandb.ai/arnavnmehta1-nutanix/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/arnavnmehta1-nutanix/trl' target=\"_blank\">https://wandb.ai/arnavnmehta1-nutanix/trl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/arnavnmehta1-nutanix/trl/runs/bkzr6a9c' target=\"_blank\">https://wandb.ai/arnavnmehta1-nutanix/trl/runs/bkzr6a9c</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ensure_dir(path):\n",
        "    Path(path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "save_dir = \"./ppo-model\"\n",
        "checkpoint_prefix = \"checkpoint\""
      ],
      "metadata": {
        "id": "HPV7s5ZVVNzn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_training_state():\n",
        "    save_dir = Path(save_dir)\n",
        "    ckpt_dir = save_dir / f\"{checkpoint_prefix}\"\n",
        "    ensure_dir(ckpt_dir)\n",
        "\n",
        "    model_to_save = policy_model\n",
        "    peft_save_dir = ckpt_dir / \"adapter\"\n",
        "    model_to_save.save_pretrained(peft_save_dir)\n",
        "\n",
        "    print(f\"Saved checkpoint to {ckpt_dir}\")"
      ],
      "metadata": {
        "id": "vKFn_evnVDW8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_kwargs = {\n",
        "    \"min_length\": -1,\n",
        "    \"top_k\": 0.0,\n",
        "    \"top_p\": 1.0,\n",
        "    \"do_sample\": True,\n",
        "    \"pad_token_id\": tokenizer.eos_token_id,\n",
        "    \"max_new_tokens\": 128, # Reduced to prevent OOM,\n",
        "    \"temperature\": 0.8,  # Add temperature for more stable sampling\n",
        "    \"repetition_penalty\": 1.2  # Prevent repetition\n",
        "}"
      ],
      "metadata": {
        "id": "Qlskk6wsWYfw"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\".*right-padding was detected.*\")"
      ],
      "metadata": {
        "id": "ICQHFxquobLm"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
        "\n",
        "    #Fix the shape, it should be a list of 4 tensors, each (128, )\n",
        "    query_tensors_batch = batch[\"input_ids\"]\n",
        "    query_tensor_2d = torch.stack(query_tensors_batch)\n",
        "    query_tensor_correct = query_tensor_2d.transpose(0, 1)\n",
        "    query_tensors = [query_tensor_correct[i] for i in range(query_tensor_correct.size(0))]\n",
        "\n",
        "    # Step 2: Remove padding tokens from queries before generation\n",
        "    unpadded_queries = []\n",
        "    for i, query in enumerate(query_tensors):\n",
        "        non_pad_mask = query != tokenizer.pad_token_id\n",
        "        unpadded_query = query[non_pad_mask]\n",
        "        unpadded_queries.append(unpadded_query)\n",
        "        #print(f\"Query {i}: padded_length={len(query)}, actual_length={len(unpadded_query)}\")\n",
        "\n",
        "    response_tensors_full = ppo_trainer.generate(unpadded_queries, **generation_kwargs)\n",
        "\n",
        "    # Step 4: Extract only the response tokens\n",
        "    response_only_tensors = []\n",
        "    for i, full_response in enumerate(response_tensors_full):\n",
        "        query_length = len(unpadded_queries[i])\n",
        "        response_length = len(full_response) - query_length\n",
        "\n",
        "        #print(f\"Sequence {i}: query_length={query_length}, full_response_length={len(full_response)}, response_length={response_length}\")\n",
        "\n",
        "        if response_length > 0:\n",
        "            response_only = full_response[query_length:]\n",
        "        else:\n",
        "            # Fallback if something goes wrong\n",
        "            print(\"Something is wrong, the response length is 0\")\n",
        "            response_only = torch.tensor([tokenizer.eos_token_id], device=full_response.device)\n",
        "\n",
        "        response_only_tensors.append(response_only)\n",
        "\n",
        "    # Step 5: Decode and verify responses\n",
        "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_only_tensors]\n",
        "\n",
        "    # # Print actual responses to verify they're not just EOS\n",
        "    # for i, (query, resp) in enumerate(zip(batch[\"query\"], batch[\"response\"])):\n",
        "    #     print(f\"Response {i}: '{resp}' (query: '{query[:50]}...')\")\n",
        "\n",
        "    # Step 6: Compute rewards\n",
        "    texts = [q + r for q, r in zip(batch[\"query\"], batch[\"response\"])]\n",
        "    with torch.no_grad():\n",
        "        reward_inputs = reward_tokenizer(\n",
        "            texts, padding=True, truncation=True,\n",
        "            return_tensors=\"pt\", max_length=384\n",
        "        ).to(device)\n",
        "\n",
        "        rewards = reward_model(**reward_inputs).logits.squeeze(-1)\n",
        "        if torch.isnan(rewards).any():\n",
        "          rewards = torch.nan_to_num(rewards, nan=0.0)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n",
        "        rewards = rewards.clamp(-3, 3)\n",
        "        rewards = [r for r in rewards]\n",
        "\n",
        "    # Final check\n",
        "    #print(f\"Final - Response lengths: {[len(r) for r in response_only_tensors]}\")\n",
        "\n",
        "    # Use the original padded queries for PPO step (as expected by the trainer)\n",
        "    stats = ppo_trainer.step(query_tensors, response_only_tensors, rewards)\n",
        "    ppo_trainer.log_stats(stats, batch, rewards)\n",
        "\n",
        "ppo_trainer.save_model(\"ppo_model\")\n",
        "save_training_state()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "rpqbvAnfWg8H",
        "outputId": "f3a32368-412f-4c2e-99d1-a8df49134c3d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -5.10 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "3it [00:15,  5.02s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -6.34 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "4it [00:20,  5.19s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -3.81 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "5it [00:25,  5.07s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -12.43 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "6it [00:30,  5.18s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -7.59 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "7it [00:35,  5.08s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -2.04 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "8it [00:40,  5.01s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -12.03 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "10it [00:51,  5.18s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -10.39 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "11it [00:56,  5.19s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -5.83 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "12it [01:04,  5.99s/it]/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py:1313: UserWarning: KL divergence is starting to become negative: -4.53 - this might be a precursor for failed training. sometimes this happens because the generation kwargs are not correctly set. Please make sure that the generation kwargs are set correctly, or review your training hyperparameters.\n",
            "  warnings.warn(\n",
            "13it [01:13,  5.69s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1604549491.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m# Use the original padded queries for PPO step (as expected by the trainer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_only_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mppo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mppo_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ppo_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/trl/trainer/ppo_trainer.py\u001b[0m in \u001b[0;36mlog_stats\u001b[0;34m(self, stats, batch, rewards, columns_to_log)\u001b[0m\n\u001b[1;32m   1413\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             self.accelerator.log(\n\u001b[0m\u001b[1;32m   1416\u001b[0m                 \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m                 \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_step\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_with\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"tensorboard\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPartialState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_inner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, values, step, log_kwargs)\u001b[0m\n\u001b[1;32m   3269\u001b[0m         \"\"\"\n\u001b[1;32m   3270\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtracker\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3271\u001b[0;31m             \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlog_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/tracking.py\u001b[0m in \u001b[0;36mexecute_on_main_process\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mPartialState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexecute_on_main_process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/accelerate/tracking.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, values, step, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0mAdditional\u001b[0m \u001b[0mkey\u001b[0m \u001b[0mword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0malong\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \"\"\"\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Successfully logged to WandB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwb_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_finished\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         message = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0m_is_attaching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(self, data, step, commit)\u001b[0m\n\u001b[1;32m   2026\u001b[0m                 \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m             )\n\u001b[0;32m-> 2028\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_log_to_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_log\u001b[0;34m(self, data, step, commit)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Key values passed to `wandb.log` must be strings.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partial_history_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwb_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_partial_history_callback\u001b[0;34m(self, data, step, commit)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0mnot_using_tensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tensorboard\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m         self._backend.interface.publish_partial_history(\n\u001b[0m\u001b[1;32m   1567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_partial_history\u001b[0;34m(self, run, data, user_step, step, flush, publish_step)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0mpublish_step\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     ) -> None:\n\u001b[0;32m--> 713\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory_dict_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_copy_err\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_step\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/data_types/utils.py\u001b[0m in \u001b[0;36mhistory_dict_to_json\u001b[0;34m(run, payload, step, ignore_copy_err)\u001b[0m\n\u001b[1;32m     52\u001b[0m             )\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             payload[key] = val_to_json(\n\u001b[0m\u001b[1;32m     55\u001b[0m                 \u001b[0mrun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_copy_err\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_copy_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/data_types/utils.py\u001b[0m in \u001b[0;36mval_to_json\u001b[0;34m(run, key, val, namespace, ignore_copy_err)\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0;34m\"joined-table\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             ]:\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0m_log_table_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;31m# Partitioned tables and joined tables do not support being bound to runs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/data_types/utils.py\u001b[0m in \u001b[0;36m_log_table_artifact\u001b[0;34m(val, key, run)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0mart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwb_logging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_to_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_is_finished\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         message = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0m_is_attaching\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36mlog_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases, tags)\u001b[0m\n\u001b[1;32m   3173\u001b[0m             \u001b[0mAn\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mArtifact\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3174\u001b[0m         \"\"\"\n\u001b[0;32m-> 3175\u001b[0;31m         return self._log_artifact(\n\u001b[0m\u001b[1;32m   3176\u001b[0m             \u001b[0martifact_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3177\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_log_artifact\u001b[0;34m(self, artifact_or_path, name, type, aliases, tags, distributed_id, finalize, is_user_created, use_after_commit)\u001b[0m\n\u001b[1;32m   3324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3325\u001b[0m         \u001b[0martifact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistributed_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_can_log_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3327\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3328\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_assert_can_log_artifact\u001b[0;34m(self, artifact)\u001b[0m\n\u001b[1;32m   3372\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3374\u001b[0;31m             \u001b[0mpublic_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_public_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3375\u001b[0m             \u001b[0mentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublic_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3376\u001b[0m             \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpublic_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"project\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_run.py\u001b[0m in \u001b[0;36m_public_api\u001b[0;34m(self, overrides)\u001b[0m\n\u001b[1;32m   3365\u001b[0m             \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"entity\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mentity\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m             \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"project\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3367\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3369\u001b[0m     \u001b[0;31m# TODO(jhr): annotate this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/apis/public/api.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, overrides, timeout, api_key)\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0minit_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             )\n\u001b[0;32m--> 321\u001b[0;31m             wandb_login._verify_login(\n\u001b[0m\u001b[1;32m    322\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"base_url\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_verify_login\u001b[0;34m(key, base_url)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0mis_api_key_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         raise AuthenticationError(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/apis/internal.py\u001b[0m in \u001b[0;36mvalidate_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;34m\"\"\"Returns whether the API key stored on initialization is valid.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfile_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36mvalidate_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;34m\"\"\"Returns whether the API key stored on initialization is valid.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"query { viewer { id } }\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"viewer\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/internal/internal_api.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m\"\"\"Wrapper around execute that logs in cases of failure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/vendor/gql-0.2.0/wandb_gql/client.py\u001b[0m in \u001b[0;36m_get_result\u001b[0;34m(self, document, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mlast_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wandb/sdk/lib/gql_request.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, document, variable_values, timeout)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mdata_key\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         }\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpost_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m         \"\"\"\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Receive the response from the server\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1428\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1249\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1251\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}